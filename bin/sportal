#!/usr/bin/env python3
import argparse
import os
import signal
import subprocess
from enum import Enum
from functools import partial
from pathlib import Path


# SCRIPT CONFIG
class Colors(Enum):
    RED = "\033[31m"  # Error
    GREEN = "\033[32m"  # Success
    YELLOW = "\033[33m"  # Warning
    BLUE = "\033[34m"  # Debug
    MAGENTA = "\033[35m"  # ???
    CYAN = "\033[36m"  # Info
    WHITE = "\033[37m"
    RESET = "\033[0m"  # Resets to default color


# Envars that should be passed into sportal
# AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are handled by the --sso flag
DEPLOY_ENVS = {
    "DEPLOY_USER": "user argument for the deploy script",
    "DOCKERHUB_ACCOUNT": "docker hub account to push builds",
    "DOCKER_USERNAME": "deploy script; docker username to login",
    "DOCKER_PASSWORD": "deploy script: docker password or PAT if using MFA",
    "SSH_PRIVATE_KEY": "ssh private key to ssh onto dev stack API",
    "SSH_PUBLIC_KEY": "ssh private key to save on dev stack API",
    "DATABASE_PASSWORD": "used for api instance",
    "DJANGO_SECRET_KEY": "used for api instance",
    "SENTRY_DSN": "used for api sentry",
    "SLACK_CCDL_TEST_CHANNEL_EMAIL": "used for testing email",
    "AWS_ACCESS_KEY_ID": "AWS credential accessing input bucket or any project resources.",
    "AWS_SECRET_ACCESS_KEY": "AWS credential accessing input bucket or any project resources.",
    "ENABLE_FEATURE_PREVIEW": "Turn on in-progress features. You probably want this set to True",
    "CELLBROWSER_SECURITY_TOKEN": "Cellbrowser security token for requests.",
    "CELLBROWSER_UPLOADERS": "List of IAM User ARNS allowed to upload to cellbrowser bucket.",
}

# Everything needs access to the system env.
global env
env = os.environ.copy()


# UTILITY
def print_color(msg, color: Colors = Colors.BLUE):
    print(f"{color.value}{msg}{Colors.RESET.value}", flush=True)


print_success = partial(print_color, color=Colors.GREEN)
print_info = partial(print_color, color=Colors.BLUE)
print_help = partial(print_color, color=Colors.CYAN)
print_warning = partial(print_color, color=Colors.YELLOW)
print_error = partial(print_color, color=Colors.RED)


# Internal Methods.
def check_envs(envs: dict):
    missing_envars = [envar for envar in envs.keys() if not env.get(envar)]

    # print_error(f"Missing {len(missing_envars)} envars:")
    # for envar in missing_envars:
    print_info("--------------")
    for envar in envs.keys():
        if envar not in missing_envars:
            print_success(f"{envar} - {env.get(envar)}")
        else:
            print_error(f"{envar} - {DEPLOY_ENVS[envar]}")
    print_info("--------------")
    if missing_envars:
        print_error(f"Found {len(missing_envars)} missing envars.")
    else:
        print_success("Success! But values are not confirmed.")


def get_aws_env_from_profile(profile: str) -> bool:
    """
    Takes an AWS SSO Profile as a string.
    Adds credential envars to global env dict variable.
    """
    if not profile:
        print_warning("Running command with no AWS SSO Profile.")
        return False

    aws_cmd = [
        "aws",
        "configure",
        "export-credentials",
        "--profile",
        profile,
        "--format",
        "env-no-export",
    ]

    print_info(f"Executing Command: {' '.join(aws_cmd)}")

    # Override STDOUT
    p = subprocess.Popen(
        aws_cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )

    code = p.wait()

    if p_stderr := p.stderr:
        stderr = p_stderr.read().decode("UTF-8")

    if code != 0:
        if code == 255:
            print_help(f"You may need to login with: aws sso login --profile {profile}")
        print_error(f"Command Failed: {stderr.strip()}")
        exit(code)

    if p_stdout := p.stdout:
        stdout = p_stdout.read().decode("UTF-8")

    # Mutate globel env dict variable
    for line in stdout.split("\n"):
        if line:
            key, value = line.split("=", 1)
            env[key] = value

    print_success("Successfully read AWS SSO credentials.")
    return True


commands_cwd = {
    "deploy:up": Path("infrastructure"),
    "deploy:down": Path("infrastructure"),
    "deploy:init": Path("infrastructure"),
    "deploy:plan": Path("infrastructure"),
    "deploy:console": Path("infrastructure"),
}

# Commands that require shell. Joined and passed as a string.
shell_commands = ["deploy:up"]

# Use the correct docker .env file by default.
docker_compose = ["docker", "compose", "--env-file", "./docker-compose.env"]
run = docker_compose + ["run", "--rm"]
run_api = run + ["api"]
run_postgres = run + ["postgres", "psql", "-h", "postgres", "-U", "postgres"]
manage = run_api + ["python3", "manage.py"]

command_descriptions = {
    # print envars available in this shell
    "debug:env": "Show status of envars that are passed to commands.",
    "docker:compose": "Same as 'docker compose' but handles passing env to containers.",
    "postgres:cli": "Local postgres shell",
    "postgres:drop": "Wipes local postgress db.",
    "api:run": "Start local API.",
    "api:manage": "Run local API management command. Requires manage command name as argument.",
    "api:test": "Run API tests.",
    "api:graphmodels": "Update the models.dot file.",
    "api:lint:black": "Lint API python code with black.",
    "deploy:up": "Spin up a dev stack. Requires successful debug:env.",
    "deploy:down": "Tear down existing dev stack.",
    "deploy:init": "Terraform init via the deploy command.",
    "deploy:plan": "Terraform plan via the deploy command.",
    "deploy:console": (
        "Access a terraform console to help test data structures."
        "Use --save-plan to save to infrastructure/PLAN."
        "View with `terraform show PLAN`"
    ),
}

# All available commands and their execution.
deploy = [
    "python3",
    "deploy.py",
    "--stage",
    "dev",
    "--user",
    os.environ.get("DEPLOY_USER"),
    "--dockerhub-account",
    os.environ.get("DOCKERHUB_ACCOUNT"),
    "--system-version",
    "$(git rev-parse HEAD)",
    "--project",
]

commands = {
    # print envars available in this shell
    "debug:env": [partial(check_envs, DEPLOY_ENVS)],
    "docker:compose": docker_compose,  # up / down / etc
    "postgres:cli": run_postgres + ["-d", "postgres"],
    "postgres:drop": run_postgres
    + ["-a", "-c", "DROP SCHEMA public CASCADE;CREATE SCHEMA public;"],
    "api:run": run_api,
    "api:manage": manage,
    "api:test": run_api + ["bash", "./run_tests.sh"],
    "api:graphmodels": manage + ["graph_models", "scpca_portal", ">", "models.dot"],
    "api:lint:black": ["black", "--line-length=100", "--exclude=volumes_postgres", "."],
    "deploy:up": deploy,
    "deploy:down": deploy + ["--destroy"],
    "deploy:init": deploy + ["--init"],
    "deploy:plan": deploy + ["--plan"],
    "deploy:console": deploy + ["--console"],
}


# Arguments
parser = argparse.ArgumentParser(
    usage="sportal [--sso PROFILE_NAME] [command] [...command_args] [--help]",
    description="ScPCA Portal Helper Commands. Expected to be called from project root.",
    epilog="Run `sportal debug:env` to ensure your environment is set up correctly.",
)
parser.formatter_class = argparse.RawTextHelpFormatter
parser.add_argument(
    "--sso", help="The AWS SSO profile to use for this command. Must be before command."
)
parser.add_argument(
    "command",
    metavar="command",
    choices=commands.keys(),
    help="\n".join(
        [
            f"{key: <15} - {command_descriptions.get(key, 'No description available.')}"
            for key in commands.keys()
        ]
    ),
)
parser.add_argument(
    "command_args",
    nargs=argparse.REMAINDER,
    help="Any additional arguments will be passed to the command.",
)


# Sportal Command
if __name__ == "__main__":
    # Exit if not called from project root.
    if not Path("bin/sportal").exists():
        print_error("Please call sportal from the project's root")
        exit(1)

    args = parser.parse_args()

    # update global env dict variable
    get_aws_env_from_profile(args.sso)

    # get command as list of parts
    cmd = commands.get(args.command, []) + args.command_args
    cwd = commands_cwd.get(args.command, Path(".")).absolute()

    if hasattr(cmd[0], "__call__"):
        cmd[0]()
        exit(0)

    cmd_str = " ".join(cmd)

    print_info(f"Command directory: {cwd.absolute()}")
    print_info(f"Command: {cmd_str}")

    # some commands may have shell substitutions
    is_shell = args.command in shell_commands

    try:
        p = subprocess.Popen(cmd_str if is_shell else cmd, env=env, cwd=cwd, shell=is_shell)
        p.wait()
        exit(p.returncode)

    except KeyboardInterrupt:
        p.send_signal(signal.SIGINT)
        exit(p.returncode)

    except Exception as e:
        print_error(e)
        exit(1)
